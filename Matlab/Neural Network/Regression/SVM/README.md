### SVM回归详细介绍

#### 什么是SVM回归？

**SVM回归**（支持向量机回归，Support Vector Machine Regression）是一种基于**支持向量机（Support Vector Machine, SVM）**的回归方法。SVM回归通过在高维特征空间中寻找一个最优的回归函数，能够有效地处理线性和非线性回归问题。它通过引入核函数（如径向基函数核、多项式核等）将输入数据映射到高维空间，从而捕捉数据中的复杂模式。SVM回归具有良好的泛化能力，能够在小样本、高维度的数据集上表现出色。

#### SVM回归的组成部分

1. **输入层**：
   - 接收输入数据的特征向量，每个节点对应一个特征。

2. **核函数（Kernel Function）**：
   - 将输入数据映射到高维特征空间，以处理非线性关系。
   - 常用的核函数包括径向基函数核（RBF核）、线性核、多项式核等。

3. **支持向量**：
   - 决定回归函数的关键数据点，这些点位于回归函数的边界或在容差范围内。

4. **回归函数**：
   - 在高维空间中寻找一个最优的超平面，以最小化预测误差。

#### SVM回归的工作原理

SVM回归通过以下步骤实现回归任务：

1. **数据准备与预处理**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建SVM回归模型**：
   - **选择核函数**：根据数据的特性选择合适的核函数，如RBF核、多项式核等。
   - **设定超参数**：
     - **惩罚因子（C）**：控制模型对误差的容忍度，较大的C值会减少训练误差，但可能导致过拟合。
     - **核函数参数（γ）**：如RBF核中的γ值，控制数据点在高维空间中的影响范围。

3. **模型训练与预测**：
   - 使用训练集数据训练SVM回归模型，确定支持向量和回归函数。
   - 使用训练好的模型对测试集数据进行回归预测，得到预测结果。

4. **模型评估与优化**：
   - 计算预测误差和其他性能指标（如RMSE、R²、MAE等），评估模型的回归准确性和泛化能力。
   - 调整SVM回归的超参数（如C、γ），优化模型性能。

5. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **误差曲线**：绘制预测误差随模型复杂度变化的曲线，观察模型的性能趋势。
   - **特征重要性**：通过分析支持向量的分布和影响，评估特征对模型预测的贡献。

#### SVM回归的优势

1. **处理非线性关系**：
   - 通过核函数将数据映射到高维空间，能够有效捕捉输入特征与目标变量之间的非线性关系。

2. **良好的泛化能力**：
   - SVM回归通过最大化边界间隔，增强模型在未见数据上的泛化能力，减少过拟合风险。

3. **适用于高维数据**：
   - 能够在高维特征空间中有效工作，适用于特征数量多的数据集。

4. **鲁棒性强**：
   - 对于噪声和异常值具有较强的鲁棒性，能够在存在噪声的数据中保持良好的预测性能。

5. **支持向量选择**：
   - 只依赖于支持向量，减少模型复杂度，提高计算效率。

#### SVM回归的应用

SVM回归广泛应用于各类需要高精度预测和拟合的领域，包括但不限于：

1. **金融预测**：
   - **股票价格预测**：预测股票市场的未来价格走势。
   - **经济指标预测**：预测GDP、通胀率等宏观经济指标。

2. **工程与制造**：
   - **设备故障预测**：预测设备的潜在故障，进行预防性维护。
   - **质量控制**：拟合和预测制造过程中关键参数，确保产品质量。

3. **环境科学**：
   - **污染物浓度预测**：预测空气或水体中的污染物浓度，进行环境监测。
   - **气象预测**：预测未来的气温、降水量等气象指标。

4. **医疗健康**：
   - **疾病风险预测**：预测个体患某种疾病的风险。
   - **医疗费用预测**：预测患者的医疗费用支出。

5. **市场营销**：
   - **销售预测**：预测产品的未来销售量，优化库存管理。
   - **客户需求预测**：预测客户的购买行为和需求变化，制定营销策略。

#### 如何使用SVM回归

使用SVM回归模型主要包括以下步骤：

1. **准备数据集**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建SVM回归模型**：
   - **选择核函数**：根据数据的特性选择合适的核函数，如RBF核、多项式核等。
   - **设定超参数**：设定惩罚因子（C）和核函数参数（γ），控制模型的复杂度和拟合能力。

3. **模型训练与预测**：
   - 使用训练集数据训练SVM回归模型，确定支持向量和回归函数。
   - 使用训练好的模型对测试集数据进行回归预测，得到预测结果。

4. **模型评估与优化**：
   - 计算预测误差和其他性能指标（如RMSE、R²、MAE等），评估模型的回归准确性和泛化能力。
   - 调整SVM回归的超参数（如C、γ），优化模型性能。

5. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **误差曲线**：绘制预测误差随模型复杂度变化的曲线，观察模型的性能趋势。
   - **特征重要性**：通过分析支持向量的分布和影响，评估特征对模型预测的贡献。

通过理解和应用上述SVM回归模型，用户可以有效地处理各种回归任务，充分发挥支持向量机在高维空间中寻找最优回归函数的优势，提升模型的预测准确性和鲁棒性。

---

### 代码简介

该MATLAB代码实现了基于**支持向量机（Support Vector Machine, SVM）**的回归算法，简称“SVM回归”。主要流程如下：

1. **数据预处理**：
   - 导入数据集，并随机打乱数据顺序。
   - 将数据集划分为训练集和测试集。
   - 对输入数据和目标变量进行归一化处理，以提高训练效果和稳定性。

2. **SVM模型构建与训练**：
   - 使用`svmtrain`函数创建SVM回归模型，设定惩罚因子（C）、核函数参数（γ）等超参数。
   - 训练模型，确定支持向量和回归函数。

3. **结果分析与可视化**：
   - 使用训练好的SVM模型对训练集和测试集进行预测。
   - 计算并显示相关回归性能指标（RMSE、R²、MAE、MBE、MAPE）。
   - 绘制训练集和测试集的真实值与预测值对比图、误差曲线以及散点图，直观展示回归效果。

以下是包含详细中文注释的SVM回归MATLAB代码。

---

### MATLAB代码（添加详细中文注释）

```matlab
%% 初始化
clear                % 清除工作区中的所有变量
close all            % 关闭所有打开的图形窗口
clc                  % 清空命令行窗口
warning off          % 关闭所有警告信息

%% 导入数据
res = xlsread('数据集.xlsx');  % 从Excel文件中读取数据，假设最后一列为目标变量

%% 数据分析
num_size = 0.7;                              % 设定训练集占数据集的比例（70%训练集，30%测试集）
outdim = 1;                                  % 最后一列为输出（目标变量）
num_samples = size(res, 1);                  % 计算样本个数（数据集中的行数）
res = res(randperm(num_samples), :);         % 随机打乱数据集顺序，以避免数据排序带来的偏差（如果不希望打乱可注释该行）
num_train_s = round(num_size * num_samples); % 计算训练集样本个数（四舍五入）
f_ = size(res, 2) - outdim;                  % 输入特征维度（总列数减去输出维度）

%% 划分训练集和测试集
P_train = res(1:num_train_s, 1:f_)';         % 训练集输入，转置使每列为一个样本 (f_ × M)
T_train = res(1:num_train_s, f_+1:end)';     % 训练集输出，转置使每列为一个样本 (outdim × M)
M = size(P_train, 2);                        % 训练集样本数

P_test = res(num_train_s+1:end, 1:f_)';      % 测试集输入，转置使每列为一个样本 (f_ × N)
T_test = res(num_train_s+1:end, f_+1:end)';  % 测试集输出，转置使每列为一个样本 (outdim × N)
N = size(P_test, 2);                         % 测试集样本数

%% 数据归一化
[p_train, ps_input] = mapminmax(P_train, 0, 1);         % 对训练集输入进行归一化，范围[0,1]
p_test = mapminmax('apply', P_test, ps_input);         % 使用训练集的归一化参数对测试集输入进行归一化

[t_train, ps_output] = mapminmax(T_train, 0, 1);         % 对训练集输出进行归一化，范围[0,1]
t_test = mapminmax('apply', T_test, ps_output);         % 使用训练集的归一化参数对测试集输出进行归一化

%% 转置以适应模型
p_train = p_train'; p_test = p_test';    % 转置输入数据，使每行为一个样本
t_train = t_train'; t_test = t_test';    % 转置输出数据，使每行为一个样本

%% 创建模型
c = 4.0;    % 惩罚因子（C），控制模型对误差的容忍度
g = 0.8;    % 径向基函数参数（gamma），控制RBF核的宽度
cmd = [' -t 2',' -c ',num2str(c),' -g ',num2str(g),' -s 3 -p 0.01']; % 构建SVM命令参数字符串
model = svmtrain(t_train, p_train, cmd);    % 使用训练集数据训练SVM回归模型

%% 仿真预测
[t_sim1, error_1] = svmpredict(t_train, p_train, model); % 使用训练集数据进行预测，得到训练集预测结果和误差
[t_sim2, error_2] = svmpredict(t_test , p_test , model);  % 使用测试集数据进行预测，得到测试集预测结果和误差

%% 数据反归一化
T_sim1 = mapminmax('reverse', t_sim1, ps_output);  % 将训练集预测结果反归一化，恢复到原始尺度
T_sim2 = mapminmax('reverse', t_sim2, ps_output);  % 将测试集预测结果反归一化，恢复到原始尺度

%% 均方根误差（RMSE）
error1 = sqrt(sum((T_sim1' - T_train).^2) ./ M);  % 计算训练集的均方根误差（RMSE）
error2 = sqrt(sum((T_sim2' - T_test ).^2) ./ N);  % 计算测试集的均方根误差（RMSE）

%% 绘图
% 绘制训练集预测结果对比图
figure
plot(1:M, T_train, 'r-*', 1:M, T_sim1, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线，红色星号为真实值，蓝色圆圈为预测值
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'训练集预测结果对比'; ['RMSE=' num2str(error1)]};      % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, M])                                                     % 设置X轴范围
grid                                                             % 显示网格

% 绘制测试集预测结果对比图
figure
plot(1:N, T_test, 'r-*', 1:N, T_sim2, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线，红色星号为真实值，蓝色圆圈为预测值
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'测试集预测结果对比'; ['RMSE=' num2str(error2)]};       % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, N])                                                     % 设置X轴范围
grid                                                             % 显示网格

%% 绘制误差曲线
figure
plot(1:trees, oobError(net), 'b-', 'LineWidth', 1)          % 绘制袋外误差曲线，展示随着决策树数量增加，误差的变化
legend('误差曲线')                                           % 添加图例
xlabel('决策树数目')                                         % 设置X轴标签
ylabel('误差')                                               % 设置Y轴标签
xlim([1, trees])                                             % 设置X轴范围
grid                                                         % 显示网格

%% 绘制特征重要性
figure
bar(importance)                                              % 绘制特征重要性柱状图
legend('重要性')                                             % 添加图例
xlabel('特征')                                               % 设置X轴标签
ylabel('重要性')                                             % 设置Y轴标签

%% 相关指标计算
% 决定系数（R²）
R1 = 1 - norm(T_train - T_sim1')^2 / norm(T_train - mean(T_train))^2;  % 计算训练集的决定系数R²
R2 = 1 - norm(T_test  - T_sim2')^2 / norm(T_test  - mean(T_test ))^2;  % 计算测试集的决定系数R²

disp(['训练集数据的R²为：', num2str(R1)])  % 显示训练集的R²
disp(['测试集数据的R²为：', num2str(R2)])  % 显示测试集的R²

% 平均绝对误差（MAE）
mae1 = sum(abs(T_sim1' - T_train)) ./ M;  % 计算训练集的平均绝对误差MAE
mae2 = sum(abs(T_sim2' - T_test )) ./ N;  % 计算测试集的平均绝对误差MAE

disp(['训练集数据的MAE为：', num2str(mae1)])  % 显示训练集的MAE
disp(['测试集数据的MAE为：', num2str(mae2)])  % 显示测试集的MAE

% 平均偏差误差（MBE）
mbe1 = sum(T_sim1' - T_train) ./ M ;  % 计算训练集的平均偏差误差MBE
mbe2 = sum(T_sim2' - T_test ) ./ N ;  % 计算测试集的平均偏差误差MBE

disp(['训练集数据的MBE为：', num2str(mbe1)])  % 显示训练集的MBE
disp(['测试集数据的MBE为：', num2str(mbe2)])  % 显示测试集的MBE

% 平均绝对百分比误差（MAPE）
mape1 = sum(abs((T_sim1' - T_train)./T_train)) ./ M ;  % 计算训练集的平均绝对百分比误差MAPE
mape2 = sum(abs((T_sim2' - T_test )./T_test )) ./ N ;  % 计算测试集的平均绝对百分比误差MAPE

disp(['训练集数据的MAPE为：', num2str(mape1)])  % 显示训练集的MAPE
disp(['测试集数据的MAPE为：', num2str(mape2)])  % 显示测试集的MAPE

% 均方根误差（RMSE）
disp(['训练集数据的RMSE为：', num2str(error1)])  % 显示训练集的RMSE
disp(['测试集数据的RMSE为：', num2str(error2)])  % 显示测试集的RMSE

%% 绘制散点图
sz = 25;       % 设置散点大小
c = 'b';       % 设置散点颜色为蓝色

% 绘制训练集散点图
figure
scatter(T_train, T_sim1, sz, c)              % 绘制训练集真实值与预测值的散点图，蓝色散点表示预测结果
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线），黑色虚线表示
xlabel('训练集真实值');                        % 设置X轴标签
ylabel('训练集预测值');                        % 设置Y轴标签
xlim([min(T_train) max(T_train)])              % 设置X轴范围
ylim([min(T_sim1) max(T_sim1)])                % 设置Y轴范围
title('训练集预测值 vs. 训练集真实值')            % 设置图形标题

% 绘制测试集散点图
figure
scatter(T_test, T_sim2, sz, c)               % 绘制测试集真实值与预测值的散点图，蓝色散点表示预测结果
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线），黑色虚线表示
xlabel('测试集真实值');                         % 设置X轴标签
ylabel('测试集预测值');                         % 设置Y轴标签
xlim([min(T_test) max(T_test)])                 % 设置X轴范围
ylim([min(T_sim2) max(T_sim2)])                 % 设置Y轴范围
title('测试集预测值 vs. 测试集真实值')             % 设置图形标题
```

---

### 代码说明

#### 1. 初始化

```matlab
clear                % 清除工作区中的所有变量
close all            % 关闭所有打开的图形窗口
clc                  % 清空命令行窗口
warning off          % 关闭所有警告信息
```

- **clear**：清除工作区中的所有变量，确保代码运行环境的干净。
- **close all**：关闭所有打开的图形窗口，避免之前的图形干扰。
- **clc**：清空命令行窗口，提升可读性。
- **warning off**：关闭所有警告信息，避免在代码运行过程中显示不必要的警告。

#### 2. 导入数据

```matlab
res = xlsread('数据集.xlsx');  % 从Excel文件中读取数据，假设最后一列为目标变量
```

- **xlsread**：从指定的Excel文件`数据集.xlsx`中读取数据。
- **res**：存储读取的数据矩阵，假设数据集的最后一列为目标变量（需要预测的值），其他列为输入特征。

#### 3. 数据分析

```matlab
num_size = 0.7;                              % 设定训练集占数据集的比例（70%训练集，30%测试集）
outdim = 1;                                  % 最后一列为输出（目标变量）
num_samples = size(res, 1);                  % 计算样本个数（数据集中的行数）
res = res(randperm(num_samples), :);         % 随机打乱数据集顺序，以避免数据排序带来的偏差（如果不希望打乱可注释该行）
num_train_s = round(num_size * num_samples); % 计算训练集样本个数（四舍五入）
f_ = size(res, 2) - outdim;                  % 输入特征维度（总列数减去输出维度）
```

- **num_size**：设定训练集占数据集的比例为70%。
- **outdim**：设定数据集的最后一列为输出（目标变量）。
- **num_samples**：计算数据集中的样本总数，即数据集的行数。
- **randperm**：随机打乱数据集的顺序，避免数据排序带来的偏差。如果不希望打乱数据集，可以注释掉该行代码。
- **num_train_s**：计算训练集的样本数量，通过`round`函数对训练集比例与总样本数的乘积进行四舍五入。
- **f_**：计算输入特征的维度，即数据集的总列数减去输出维度。

#### 4. 划分训练集和测试集

```matlab
P_train = res(1:num_train_s, 1:f_)';         % 训练集输入，转置使每列为一个样本 (f_ × M)
T_train = res(1:num_train_s, f_+1:end)';     % 训练集输出，转置使每列为一个样本 (outdim × M)
M = size(P_train, 2);                        % 训练集样本数

P_test = res(num_train_s+1:end, 1:f_)';      % 测试集输入，转置使每列为一个样本 (f_ × N)
T_test = res(num_train_s+1:end, f_+1:end)';  % 测试集输出，转置使每列为一个样本 (outdim × N)
N = size(P_test, 2);                         % 测试集样本数
```

- **P_train**：提取前`num_train_s`个样本的输入特征，并进行转置，使每列为一个样本。
- **T_train**：提取前`num_train_s`个样本的输出（目标变量），并进行转置，使每列为一个样本。
- **M**：获取训练集的样本数量。
- **P_test**：提取剩余样本的输入特征，并进行转置，使每列为一个样本。
- **T_test**：提取剩余样本的输出（目标变量），并进行转置，使每列为一个样本。
- **N**：获取测试集的样本数量。

#### 5. 数据归一化

```matlab
[p_train, ps_input] = mapminmax(P_train, 0, 1);         % 对训练集输入进行归一化，范围[0,1]
p_test = mapminmax('apply', P_test, ps_input);         % 使用训练集的归一化参数对测试集输入进行归一化

[t_train, ps_output] = mapminmax(T_train, 0, 1);         % 对训练集输出进行归一化，范围[0,1]
t_test = mapminmax('apply', T_test, ps_output);         % 使用训练集的归一化参数对测试集输出进行归一化
```

- **mapminmax**：使用`mapminmax`函数将数据缩放到指定的范围内（这里为[0,1]）。
- **p_train**：归一化后的训练集输入数据。
- **ps_input**：保存归一化参数，以便对测试集数据进行相同的归一化处理。
- **p_test**：使用训练集的归一化参数对测试集输入数据进行归一化，确保训练集和测试集的数据尺度一致。
- **t_train**：归一化后的训练集输出数据。
- **ps_output**：保存归一化参数，以便对测试集输出数据进行相同的归一化处理。
- **t_test**：使用训练集的归一化参数对测试集输出数据进行归一化。

#### 6. 转置以适应模型

```matlab
p_train = p_train'; p_test = p_test';    % 转置输入数据，使每行为一个样本
t_train = t_train'; t_test = t_test';    % 转置输出数据，使每行为一个样本
```

- **转置**：将输入和输出数据进行转置，使每行为一个样本，符合`svmtrain`和`svmpredict`函数的输入要求。

#### 7. 创建模型

```matlab
c = 4.0;    % 惩罚因子（C），控制模型对误差的容忍度
g = 0.8;    % 径向基函数参数（gamma），控制RBF核的宽度
cmd = [' -t 2',' -c ',num2str(c),' -g ',num2str(g),' -s 3 -p 0.01']; % 构建SVM命令参数字符串
model = svmtrain(t_train, p_train, cmd);    % 使用训练集数据训练SVM回归模型
```

- **c**：设定惩罚因子（C），控制模型对误差的容忍度。较大的C值会减少训练误差，但可能导致过拟合。
- **g**：设定径向基函数参数（gamma），控制RBF核的宽度。较大的gamma值会使核函数更窄，影响数据点的影响范围。
- **cmd**：构建SVM命令参数字符串，包括核函数类型（-t 2表示RBF核）、惩罚因子（-c）、核函数参数（-g）、支持向量机类型（-s 3表示epsilon-SVR）、以及容差参数（-p 0.01）。
- **svmtrain**：使用训练集数据`p_train`和训练集输出`T_train`，以及设定的命令参数`cmd`，训练SVM回归模型，得到模型对象`model`。

#### 8. 仿真预测

```matlab
[t_sim1, error_1] = svmpredict(t_train, p_train, model); % 使用训练集数据进行预测，得到训练集预测结果和误差
[t_sim2, error_2] = svmpredict(t_test , p_test , model);  % 使用测试集数据进行预测，得到测试集预测结果和误差
```

- **svmpredict**：使用训练好的SVM回归模型对输入数据进行预测。
  - **t_sim1**：训练集的预测结果。
  - **error_1**：训练集预测的误差。
  - **t_sim2**：测试集的预测结果。
  - **error_2**：测试集预测的误差。

#### 9. 数据反归一化

```matlab
T_sim1 = mapminmax('reverse', t_sim1, ps_output);  % 将训练集预测结果反归一化，恢复到原始尺度
T_sim2 = mapminmax('reverse', t_sim2, ps_output);  % 将测试集预测结果反归一化，恢复到原始尺度
```

- **mapminmax('reverse', ...)**：使用`mapminmax`函数将预测结果反归一化，恢复到原始数据的尺度。
- **T_sim1**：训练集预测结果，恢复到原始尺度。
- **T_sim2**：测试集预测结果，恢复到原始尺度。

#### 10. 均方根误差（RMSE）

```matlab
error1 = sqrt(sum((T_sim1' - T_train).^2) ./ M);  % 计算训练集的均方根误差（RMSE）
error2 = sqrt(sum((T_sim2' - T_test ).^2) ./ N);  % 计算测试集的均方根误差（RMSE）
```

- **RMSE**：均方根误差，衡量模型预测值与真实值之间的平均差异。
- **error1**：训练集的RMSE，计算公式为：
  \[
  RMSE = \sqrt{\frac{1}{M} \sum_{i=1}^{M} (T_{\text{sim1}} - T_{\text{train}})^2}
  \]
- **error2**：测试集的RMSE，计算公式为：
  \[
  RMSE = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (T_{\text{sim2}} - T_{\text{test}})^2}
  \]

#### 11. 绘图

##### 绘制训练集预测结果对比图

```matlab
figure
plot(1:M, T_train, 'r-*', 1:M, T_sim1, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线，红色星号为真实值，蓝色圆圈为预测值
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'训练集预测结果对比'; ['RMSE=' num2str(error1)]};      % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, M])                                                     % 设置X轴范围
grid                                                             % 显示网格
```

- **figure**：创建新的图形窗口。
- **plot**：
  - 绘制训练集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
- **legend**：添加图例，区分真实值和预测值。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **title**：设置图形的标题，包括RMSE值。
- **xlim**：设置X轴的显示范围为[1, M]。
- **grid**：显示网格，提升图形的可读性。

##### 绘制测试集预测结果对比图

```matlab
figure
plot(1:N, T_test, 'r-*', 1:N, T_sim2, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线，红色星号为真实值，蓝色圆圈为预测值
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'测试集预测结果对比'; ['RMSE=' num2str(error2)]};       % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, N])                                                     % 设置X轴范围
grid                                                             % 显示网格
```

- **figure**：创建新的图形窗口。
- **plot**：
  - 绘制测试集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
- **legend**：添加图例，区分真实值和预测值。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **title**：设置图形的标题，包括RMSE值。
- **xlim**：设置X轴的显示范围为[1, N]。
- **grid**：显示网格，提升图形的可读性。

#### 12. 绘制误差曲线

```matlab
figure
plot(1:trees, oobError(net), 'b-', 'LineWidth', 1)          % 绘制袋外误差曲线，展示随着决策树数量增加，误差的变化
legend('误差曲线')                                           % 添加图例
xlabel('决策树数目')                                         % 设置X轴标签
ylabel('误差')                                               % 设置Y轴标签
xlim([1, trees])                                             % 设置X轴范围
grid                                                         % 显示网格
```

- **figure**：创建新的图形窗口。
- **plot**：
  - 绘制袋外误差（Out-Of-Bag Error）随决策树数量增加的变化曲线，蓝色实线表示误差的变化趋势。
- **legend**：添加图例，标识误差曲线。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **xlim**：设置X轴的显示范围为[1, trees]。
- **grid**：显示网格，提升图形的可读性。

#### 13. 绘制特征重要性

```matlab
figure
bar(importance)                                              % 绘制特征重要性柱状图
legend('重要性')                                             % 添加图例
xlabel('特征')                                               % 设置X轴标签
ylabel('重要性')                                             % 设置Y轴标签
```

- **figure**：创建新的图形窗口。
- **bar**：
  - 绘制特征重要性评分的柱状图，蓝色柱子表示各特征的重要性。
- **legend**：添加图例，标识重要性。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。

#### 14. 相关指标计算

```matlab
% 决定系数（R²）
R1 = 1 - norm(T_train - T_sim1')^2 / norm(T_train - mean(T_train))^2;  % 计算训练集的决定系数R²
R2 = 1 - norm(T_test  - T_sim2')^2 / norm(T_test  - mean(T_test ))^2;  % 计算测试集的决定系数R²

disp(['训练集数据的R²为：', num2str(R1)])  % 显示训练集的R²
disp(['测试集数据的R²为：', num2str(R2)])  % 显示测试集的R²

% 平均绝对误差（MAE）
mae1 = sum(abs(T_sim1' - T_train)) ./ M;  % 计算训练集的平均绝对误差MAE
mae2 = sum(abs(T_sim2' - T_test )) ./ N;  % 计算测试集的平均绝对误差MAE

disp(['训练集数据的MAE为：', num2str(mae1)])  % 显示训练集的MAE
disp(['测试集数据的MAE为：', num2str(mae2)])  % 显示测试集的MAE

% 平均偏差误差（MBE）
mbe1 = sum(T_sim1' - T_train) ./ M ;  % 计算训练集的平均偏差误差MBE
mbe2 = sum(T_sim2' - T_test ) ./ N ;  % 计算测试集的平均偏差误差MBE

disp(['训练集数据的MBE为：', num2str(mbe1)])  % 显示训练集的MBE
disp(['测试集数据的MBE为：', num2str(mbe2)])  % 显示测试集的MBE

% 平均绝对百分比误差（MAPE）
mape1 = sum(abs((T_sim1' - T_train)./T_train)) ./ M ;  % 计算训练集的平均绝对百分比误差MAPE
mape2 = sum(abs((T_sim2' - T_test )./T_test )) ./ N ;  % 计算测试集的平均绝对百分比误差MAPE

disp(['训练集数据的MAPE为：', num2str(mape1)])  % 显示训练集的MAPE
disp(['测试集数据的MAPE为：', num2str(mape2)])  % 显示测试集的MAPE

% 均方根误差（RMSE）
disp(['训练集数据的RMSE为：', num2str(error1)])  % 显示训练集的RMSE
disp(['测试集数据的RMSE为：', num2str(error2)])  % 显示测试集的RMSE
```

- **决定系数（R²）**：
  - **R1**：训练集的决定系数R²，衡量模型对训练数据的拟合程度。
  - **R2**：测试集的决定系数R²，衡量模型对测试数据的泛化能力。
  - **disp**：使用`disp`函数显示R²值。

- **平均绝对误差（MAE）**：
  - **mae1**：训练集的平均绝对误差，表示预测值与真实值之间的平均绝对差异。
  - **mae2**：测试集的平均绝对误差，表示预测值与真实值之间的平均绝对差异。
  - **disp**：使用`disp`函数显示MAE值。

- **平均偏差误差（MBE）**：
  - **mbe1**：训练集的平均偏差误差，衡量模型是否存在系统性偏差。
  - **mbe2**：测试集的平均偏差误差，衡量模型是否存在系统性偏差。
  - **disp**：使用`disp`函数显示MBE值。

- **平均绝对百分比误差（MAPE）**：
  - **mape1**：训练集的平均绝对百分比误差，表示预测值与真实值之间的平均绝对百分比差异。
  - **mape2**：测试集的平均绝对百分比误差，表示预测值与真实值之间的平均绝对百分比差异。
  - **disp**：使用`disp`函数显示MAPE值。

- **均方根误差（RMSE）**：
  - **error1**：训练集的RMSE，显示训练集的均方根误差。
  - **error2**：测试集的RMSE，显示测试集的均方根误差。
  - **disp**：使用`disp`函数显示RMSE值。

#### 15. 绘制散点图

##### 绘制训练集散点图

```matlab
figure
scatter(T_train, T_sim1, sz, c)              % 绘制训练集真实值与预测值的散点图，蓝色散点表示预测结果
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线），黑色虚线表示
xlabel('训练集真实值');                        % 设置X轴标签
ylabel('训练集预测值');                        % 设置Y轴标签
xlim([min(T_train) max(T_train)])              % 设置X轴范围
ylim([min(T_sim1) max(T_sim1)])                % 设置Y轴范围
title('训练集预测值 vs. 训练集真实值')            % 设置图形标题
```

- **figure**：创建新的图形窗口。
- **scatter**：
  - 使用`scatter`函数绘制训练集真实值与预测值的散点图，蓝色散点表示预测结果。
- **hold on**：保持当前图形，允许在同一图形上绘制多条曲线。
- **plot(xlim, ylim, '--k')**：
  - 绘制理想预测线，即真实值等于预测值的对角线，使用黑色虚线表示。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **xlim** 和 **ylim**：设置X轴和Y轴的显示范围。
- **title**：设置图形的标题，为“训练集预测值 vs. 训练集真实值”。

##### 绘制测试集散点图

```matlab
figure
scatter(T_test, T_sim2, sz, c)               % 绘制测试集真实值与预测值的散点图，蓝色散点表示预测结果
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线），黑色虚线表示
xlabel('测试集真实值');                         % 设置X轴标签
ylabel('测试集预测值');                         % 设置Y轴标签
xlim([min(T_test) max(T_test)])                 % 设置X轴范围
ylim([min(T_sim2) max(T_sim2)])                 % 设置Y轴范围
title('测试集预测值 vs. 测试集真实值')             % 设置图形标题
```

- **figure**：创建新的图形窗口。
- **scatter**：
  - 使用`scatter`函数绘制测试集真实值与预测值的散点图，蓝色散点表示预测结果。
- **hold on**：保持当前图形，允许在同一图形上绘制多条曲线。
- **plot(xlim, ylim, '--k')**：
  - 绘制理想预测线，即真实值等于预测值的对角线，使用黑色虚线表示。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **xlim** 和 **ylim**：设置X轴和Y轴的显示范围。
- **title**：设置图形的标题，为“测试集预测值 vs. 测试集真实值”。

---

### 代码使用注意事项

1. **数据集格式**：
   - **目标变量**：确保`数据集.xlsx`的最后一列为目标变量，且目标变量为数值型数据。如果目标变量为分类标签，需先进行数值编码。
   - **特征类型**：数据集的其他列应为数值型特征，适合进行归一化处理。如果特征包含类别变量，需先进行编码转换。

2. **参数调整**：
   - **惩罚因子（C）**：在代码中通过`c = 4.0`设定。根据数据集的复杂度和噪声水平调整惩罚因子，C值过大可能导致过拟合，C值过小可能导致欠拟合。
   - **径向基函数参数（gamma）**：通过`g = 0.8`设定。gamma值控制RBF核的宽度，较大的gamma值会使核函数更窄，影响模型的拟合能力；较小的gamma值会使核函数更宽，影响模型的泛化能力。
   - **支持向量机类型（-s 3）**：通过`-s 3`指定为epsilon-SVR，适用于回归问题。
   - **容差参数（-p 0.01）**：通过`-p 0.01`设定epsilon的值，控制模型的容差范围。

3. **环境要求**：
   - **MATLAB版本**：确保使用的MATLAB版本支持`svmtrain`和`svmpredict`函数。这些函数属于旧版本的Statistics and Machine Learning Toolbox。如果使用较新的MATLAB版本，建议使用`fitrsvm`和`predict`函数。
   - **工具箱**：
     - **统计与机器学习工具箱（Statistics and Machine Learning Toolbox）**：支持`svmtrain`、`svmpredict`等函数。

4. **性能优化**：
   - **数据预处理**：除了归一化处理，还可以考虑主成分分析（PCA）等降维方法，减少特征数量，提升模型训练效率和性能。
   - **超参数优化**：
     - 使用交叉验证或网格搜索方法自动调整SVM的超参数（如C、gamma），以找到最佳的参数组合，提升模型性能。
   - **核函数选择**：根据数据的特性选择合适的核函数，除了RBF核外，还可以尝试线性核、多项式核等，观察不同核函数对模型性能的影响。

5. **结果验证**：
   - **交叉验证**：采用k折交叉验证方法评估模型的稳定性和泛化能力，避免因数据划分偶然性导致的性能波动。
   - **多次运行**：由于SVM对参数敏感，建议多次运行模型，取平均性能指标，以获得更稳定的评估结果。
   - **模型对比**：将SVM回归模型与其他回归模型（如BP回归、RBF回归、随机森林回归等）进行对比，评估不同模型在相同数据集上的表现差异。

6. **性能指标理解**：
   - **决定系数（R²）**：衡量模型对数据的拟合程度，值越接近1表示模型解释变量变异的能力越强。
   - **平均绝对误差（MAE）**：表示预测值与真实值之间的平均绝对差异，值越小表示模型性能越好。
   - **平均偏差误差（MBE）**：表示预测值与真实值之间的平均差异，正值表示模型倾向于高估，负值表示模型倾向于低估。
   - **平均绝对百分比误差（MAPE）**：表示预测值与真实值之间的平均绝对百分比差异，适用于评估相对误差。
   - **均方根误差（RMSE）**：表示预测值与真实值之间的平方差的平均值的平方根，值越小表示模型性能越好。

7. **模型分析与可视化**：
   - **支持向量分析**：通过分析支持向量的分布和数量，了解模型的复杂度和拟合能力。
   - **误差曲线分析**：通过绘制误差曲线，观察模型的预测误差随模型复杂度（如决策树数量）的变化趋势，评估模型的收敛性和泛化能力。

8. **代码适应性**：
   - **模型参数调整**：根据实际数据和任务需求，调整SVM回归的参数（如C、gamma），以优化模型性能。
   - **数据格式匹配**：确保输入数据的格式与SVM回归模型的要求一致。如果输入数据为多特征的高维数据，需相应调整模型参数和数据处理方式。
   - **特征处理**：如果输入数据包含类别特征，需先进行数值编码转换，确保所有特征均为数值型数据。

通过理解和应用上述SVM回归模型，用户可以有效地处理各种回归任务，充分发挥支持向量机在高维空间中寻找最优回归函数的优势，提升模型的预测准确性和鲁棒性。
