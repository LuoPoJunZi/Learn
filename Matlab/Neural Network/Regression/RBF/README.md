### RBF回归详细介绍

#### 什么是RBF回归？

**RBF回归**（径向基函数回归，Radial Basis Function Regression）是一种基于**径向基函数神经网络（Radial Basis Function Neural Network, RBFNN）**的回归方法。RBF神经网络是一种前馈神经网络，具有单隐层结构，广泛应用于函数逼近、时间序列预测、分类和回归等领域。RBF回归通过使用径向基函数作为激活函数，能够有效地处理非线性关系，具有良好的泛化能力和快速的训练速度。

#### RBF回归的组成部分

1. **输入层**：
   - 接收输入数据的特征向量，每个节点对应一个特征。

2. **隐层（径向基函数层）**：
   - **径向基函数单元**：通常使用高斯函数作为激活函数，通过计算输入与中心点的距离来激活。
   - **中心和宽度**：每个径向基函数单元具有一个中心和一个宽度参数，用于确定函数的形状和位置。

3. **输出层**：
   - 线性组合隐层输出，实现回归任务。

#### RBF回归的工作原理

RBF回归通过以下步骤实现回归任务：

1. **数据准备与预处理**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建RBF神经网络**：
   - **网络结构设计**：确定输入层、隐层和输出层的节点数，根据问题的复杂度和数据特性设计合适的网络架构。
   - **参数初始化**：设定隐层径向基函数的中心和宽度参数，通常通过聚类算法（如K均值）确定中心。

3. **训练RBF神经网络**：
   - **隐层参数确定**：通过无监督学习方法（如K均值聚类）确定径向基函数的中心和宽度。
   - **输出层权重训练**：使用线性回归方法或最小二乘法确定输出层的权重，实现网络的线性组合。

4. **模型预测与评估**：
   - 使用训练好的RBF神经网络对测试集数据进行回归预测。
   - 计算预测误差和其他性能指标（如RMSE、R²、MAE等），评估模型的回归准确性和泛化能力。

5. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **性能指标**：计算并显示RMSE、R²、MAE、MBE、MAPE等回归性能指标，全面评估模型性能。

#### RBF回归的优势

1. **处理非线性关系**：
   - RBF回归通过径向基函数能够有效地捕捉输入特征与目标变量之间的非线性关系。

2. **快速训练速度**：
   - 隐层参数通常通过无监督学习方法确定，输出层权重通过线性回归快速计算，整体训练速度较快。

3. **良好的泛化能力**：
   - RBF神经网络具有较强的泛化能力，能够在未见数据上表现良好。

4. **简单的网络结构**：
   - RBF网络结构简单，易于理解和实现，适用于各种回归任务。

5. **适应性强**：
   - 可根据任务需求灵活调整隐层节点数和径向基函数参数，适应不同复杂度的回归问题。

#### RBF回归的应用

RBF回归广泛应用于各类需要高精度预测和拟合的领域，包括但不限于：

1. **金融预测**：
   - **股票价格预测**：预测股票市场的未来价格走势。
   - **经济指标预测**：预测GDP、通胀率等宏观经济指标。

2. **工程与制造**：
   - **设备故障预测**：预测设备的潜在故障，进行预防性维护。
   - **质量控制**：拟合和预测制造过程中关键参数，确保产品质量。

3. **环境科学**：
   - **污染物浓度预测**：预测空气或水体中的污染物浓度，进行环境监测。
   - **气象预测**：预测未来的气温、降水量等气象指标。

4. **医疗健康**：
   - **疾病风险预测**：预测个体患某种疾病的风险。
   - **医疗费用预测**：预测患者的医疗费用支出。

5. **市场营销**：
   - **销售预测**：预测产品的未来销售量，优化库存管理。
   - **客户需求预测**：预测客户的购买行为和需求变化，制定营销策略。

#### 如何使用RBF回归

使用RBF回归模型主要包括以下步骤：

1. **准备数据集**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建RBF神经网络**：
   - **设计网络结构**：确定输入层、隐层和输出层的节点数，设计合适的网络架构。
   - **隐层参数初始化**：通过聚类算法（如K均值）确定隐层径向基函数的中心和宽度。

3. **训练RBF神经网络**：
   - **隐层参数确定**：使用无监督学习方法确定径向基函数的中心和宽度。
   - **输出层权重训练**：使用线性回归方法或最小二乘法确定输出层的权重，实现网络的线性组合。

4. **模型预测与评估**：
   - 使用训练好的RBF神经网络对测试集数据进行回归预测，计算预测误差和其他性能指标，评估模型的回归准确性和泛化能力。

5. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **性能指标**：计算并显示RMSE、R²、MAE、MBE、MAPE等回归性能指标，全面评估模型性能。

通过理解和应用上述RBF回归模型，用户可以有效地处理各种回归任务，充分发挥RBF神经网络在非线性关系建模和快速训练方面的优势，提升模型的预测准确性和鲁棒性。

---

### 代码简介

该MATLAB代码实现了基于**径向基函数神经网络（RBFNN）**的回归算法，简称“RBF回归”。主要流程如下：

1. **数据预处理**：
   - 导入数据集，并随机打乱数据顺序。
   - 将数据集划分为训练集和测试集。
   - 对输入数据和目标变量进行归一化处理，以提高训练效果和稳定性。

2. **RBF网络构建与训练**：
   - 使用`newrbe`函数创建RBF神经网络，设定径向基函数的扩展速度。
   - 训练网络，确定网络的权重和偏置。

3. **结果分析与可视化**：
   - 使用训练好的RBF网络对训练集和测试集进行预测。
   - 计算并显示相关回归性能指标（RMSE、R²、MAE、MBE、MAPE）。
   - 绘制训练集和测试集的真实值与预测值对比图以及散点图，直观展示回归效果。

以下是包含详细中文注释的RBF回归MATLAB代码。

---

### MATLAB代码（添加详细中文注释）

```matlab
%% 初始化
clear                % 清除工作区变量
close all            % 关闭所有图形窗口
clc                  % 清空命令行窗口
warning off          % 关闭警告信息

%% 导入数据
res = xlsread('数据集.xlsx');  % 从Excel文件中读取数据，假设最后一列为目标变量

%% 数据分析
num_size = 0.7;                              % 设定训练集占数据集的比例（70%训练集，30%测试集）
outdim = 1;                                  % 最后一列为输出（目标变量）
num_samples = size(res, 1);                  % 计算样本个数（数据集中的行数）
res = res(randperm(num_samples), :);         % 随机打乱数据集顺序，以避免数据排序带来的偏差（如果不希望打乱可注释该行）
num_train_s = round(num_size * num_samples); % 计算训练集样本个数（四舍五入）
f_ = size(res, 2) - outdim;                  % 输入特征维度（总列数减去输出维度）

%% 划分训练集和测试集
P_train = res(1:num_train_s, 1:f_)';         % 训练集输入，转置使每列为一个样本 (f_ × M)
T_train = res(1:num_train_s, f_+1:end)';     % 训练集输出，转置使每列为一个样本 (outdim × M)
M = size(P_train, 2);                        % 训练集样本数

P_test = res(num_train_s+1:end, 1:f_)';      % 测试集输入，转置使每列为一个样本 (f_ × N)
T_test = res(num_train_s+1:end, f_+1:end)';  % 测试集输出，转置使每列为一个样本 (outdim × N)
N = size(P_test, 2);                         % 测试集样本数

%% 数据归一化
[p_train, ps_input] = mapminmax(P_train, 0, 1);         % 对训练集输入进行归一化，范围[0,1]
p_test = mapminmax('apply', P_test, ps_input);         % 使用训练集的归一化参数对测试集输入进行归一化

[t_train, ps_output] = mapminmax(T_train, 0, 1);         % 对训练集输出进行归一化，范围[0,1]
t_test = mapminmax('apply', T_test, ps_output);         % 使用训练集的归一化参数对测试集输出进行归一化

%% 创建网络
rbf_spread = 100;                           % 径向基函数的扩展速度（影响高斯函数的宽度）
net = newrbe(p_train, t_train, rbf_spread); % 创建RBF神经网络，使用训练集数据确定中心和宽度参数

%% 仿真测试
t_sim1 = sim(net, p_train);          % 使用训练集数据进行仿真预测，得到训练集预测结果
t_sim2 = sim(net, p_test );          % 使用测试集数据进行仿真预测，得到测试集预测结果

%% 数据反归一化
T_sim1 = mapminmax('reverse', t_sim1, ps_output);  % 将训练集预测结果反归一化，恢复到原始尺度
T_sim2 = mapminmax('reverse', t_sim2, ps_output);  % 将测试集预测结果反归一化，恢复到原始尺度

%% 均方根误差（RMSE）
error1 = sqrt(sum((T_sim1 - T_train).^2) ./ M);  % 计算训练集的均方根误差（RMSE）
error2 = sqrt(sum((T_sim2 - T_test ).^2) ./ N);  % 计算测试集的均方根误差（RMSE）

%% 查看网络结构
view(net)  % 可视化RBF神经网络的结构，包括输入层、隐层和输出层

%% 绘图
% 绘制训练集预测结果对比图
figure
plot(1:M, T_train, 'r-*', 1:M, T_sim1, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'训练集预测结果对比'; ['RMSE=' num2str(error1)]};      % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, M])                                                     % 设置X轴范围
grid                                                             % 显示网格

% 绘制测试集预测结果对比图
figure
plot(1:N, T_test, 'r-*', 1:N, T_sim2, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'测试集预测结果对比'; ['RMSE=' num2str(error2)]};       % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, N])                                                     % 设置X轴范围
grid                                                             % 显示网格

%% 相关指标计算
% R²
R1 = 1 - norm(T_train - T_sim1)^2 / norm(T_train - mean(T_train))^2;  % 计算训练集的决定系数R²
R2 = 1 - norm(T_test  - T_sim2)^2 / norm(T_test  - mean(T_test ))^2;  % 计算测试集的决定系数R²

disp(['训练集数据的R²为：', num2str(R1)])  % 显示训练集的R²
disp(['测试集数据的R²为：', num2str(R2)])  % 显示测试集的R²

% MAE
mae1 = sum(abs(T_sim1 - T_train)) ./ M ;  % 计算训练集的平均绝对误差MAE
mae2 = sum(abs(T_sim2 - T_test )) ./ N ;  % 计算测试集的平均绝对误差MAE

disp(['训练集数据的MAE为：', num2str(mae1)])  % 显示训练集的MAE
disp(['测试集数据的MAE为：', num2str(mae2)])  % 显示测试集的MAE

% MBE
mbe1 = sum(T_sim1 - T_train) ./ M ;  % 计算训练集的平均偏差误差MBE
mbe2 = sum(T_sim2 - T_test ) ./ N ;  % 计算测试集的平均偏差误差MBE

disp(['训练集数据的MBE为：', num2str(mbe1)])  % 显示训练集的MBE
disp(['测试集数据的MBE为：', num2str(mbe2)])  % 显示测试集的MBE

% MAPE
mape1 = sum(abs((T_sim1 - T_train)./T_train)) ./ M ;  % 计算训练集的平均绝对百分比误差MAPE
mape2 = sum(abs((T_sim2 - T_test )./T_test )) ./ N ;  % 计算测试集的平均绝对百分比误差MAPE

disp(['训练集数据的MAPE为：', num2str(mape1)])  % 显示训练集的MAPE
disp(['测试集数据的MAPE为：', num2str(mape2)])  % 显示测试集的MAPE

% RMSE
disp(['训练集数据的RMSE为：', num2str(error1)])  % 显示训练集的RMSE
disp(['测试集数据的RMSE为：', num2str(error2)])  % 显示测试集的RMSE

%% 绘制散点图
sz = 25;       % 设置散点大小
c = 'b';       % 设置散点颜色为蓝色

% 绘制训练集散点图
figure
scatter(T_train, T_sim1, sz, c)              % 绘制训练集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('训练集真实值');                        % 设置X轴标签
ylabel('训练集预测值');                        % 设置Y轴标签
xlim([min(T_train) max(T_train)])              % 设置X轴范围
ylim([min(T_sim1) max(T_sim1)])                % 设置Y轴范围
title('训练集预测值 vs. 训练集真实值')            % 设置图形标题

% 绘制测试集散点图
figure
scatter(T_test, T_sim2, sz, c)               % 绘制测试集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('测试集真实值');                         % 设置X轴标签
ylabel('测试集预测值');                         % 设置Y轴标签
xlim([min(T_test) max(T_test)])                 % 设置X轴范围
ylim([min(T_sim2) max(T_sim2)])                 % 设置Y轴范围
title('测试集预测值 vs. 测试集真实值')             % 设置图形标题
```

---

### 代码说明

#### 1. 初始化

```matlab
clear                % 清除工作区变量
close all            % 关闭所有图形窗口
clc                  % 清空命令行窗口
warning off          % 关闭警告信息
```

- **clear**：清除工作区中的所有变量，确保代码运行环境的干净。
- **close all**：关闭所有打开的图形窗口，避免干扰。
- **clc**：清空命令行窗口，提升可读性。
- **warning off**：关闭警告信息，避免在代码运行过程中显示不必要的警告。

#### 2. 导入数据

```matlab
res = xlsread('数据集.xlsx');  % 从Excel文件中读取数据，假设最后一列为目标变量
```

- **xlsread**：从指定的Excel文件`数据集.xlsx`中读取数据。
- **res**：存储读取的数据矩阵，假设数据集的最后一列为目标变量（需要预测的值），其他列为输入特征。

#### 3. 数据分析

```matlab
num_size = 0.7;                              % 设定训练集占数据集的比例（70%训练集，30%测试集）
outdim = 1;                                  % 最后一列为输出（目标变量）
num_samples = size(res, 1);                  % 计算样本个数（数据集中的行数）
res = res(randperm(num_samples), :);         % 随机打乱数据集顺序，以避免数据排序带来的偏差（如果不希望打乱可注释该行）
num_train_s = round(num_size * num_samples); % 计算训练集样本个数（四舍五入）
f_ = size(res, 2) - outdim;                  % 输入特征维度（总列数减去输出维度）
```

- **num_size**：设定训练集占数据集的比例为70%。
- **outdim**：设定数据集的最后一列为输出（目标变量）。
- **num_samples**：计算数据集中的样本总数，即数据集的行数。
- **randperm**：随机打乱数据集的顺序，避免数据排序带来的偏差。如果不希望打乱数据集，可以注释掉该行代码。
- **num_train_s**：计算训练集的样本数量，通过`round`函数对训练集比例与总样本数的乘积进行四舍五入。
- **f_**：计算输入特征的维度，即数据集的总列数减去输出维度。

#### 4. 划分训练集和测试集

```matlab
P_train = res(1:num_train_s, 1:f_)';         % 训练集输入，转置使每列为一个样本 (f_ × M)
T_train = res(1:num_train_s, f_+1:end)';     % 训练集输出，转置使每列为一个样本 (outdim × M)
M = size(P_train, 2);                        % 训练集样本数

P_test = res(num_train_s+1:end, 1:f_)';      % 测试集输入，转置使每列为一个样本 (f_ × N)
T_test = res(num_train_s+1:end, f_+1:end)';  % 测试集输出，转置使每列为一个样本 (outdim × N)
N = size(P_test, 2);                         % 测试集样本数
```

- **P_train**：提取前`num_train_s`个样本的输入特征，并进行转置，使每列为一个样本。
- **T_train**：提取前`num_train_s`个样本的输出（目标变量），并进行转置，使每列为一个样本。
- **M**：获取训练集的样本数量。
- **P_test**：提取剩余样本的输入特征，并进行转置，使每列为一个样本。
- **T_test**：提取剩余样本的输出（目标变量），并进行转置，使每列为一个样本。
- **N**：获取测试集的样本数量。

#### 5. 数据归一化

```matlab
[p_train, ps_input] = mapminmax(P_train, 0, 1);         % 对训练集输入进行归一化，范围[0,1]
p_test = mapminmax('apply', P_test, ps_input);         % 使用训练集的归一化参数对测试集输入进行归一化

[t_train, ps_output] = mapminmax(T_train, 0, 1);         % 对训练集输出进行归一化，范围[0,1]
t_test = mapminmax('apply', T_test, ps_output);         % 使用训练集的归一化参数对测试集输出进行归一化
```

- **mapminmax**：使用`mapminmax`函数将数据缩放到指定的范围内（这里为[0,1]）。
- **p_train**：归一化后的训练集输入数据。
- **ps_input**：保存归一化参数，以便对测试集数据进行相同的归一化处理。
- **p_test**：使用训练集的归一化参数对测试集输入数据进行归一化，确保训练集和测试集的数据尺度一致。
- **t_train**：归一化后的训练集输出数据。
- **ps_output**：保存归一化参数，以便对测试集输出数据进行相同的归一化处理。
- **t_test**：使用训练集的归一化参数对测试集输出数据进行归一化。

#### 6. 创建网络

```matlab
rbf_spread = 100;                           % 径向基函数的扩展速度（影响高斯函数的宽度）
net = newrbe(p_train, t_train, rbf_spread); % 创建RBF神经网络，使用训练集数据确定中心和宽度参数
```

- **rbf_spread**：设定径向基函数的扩展速度，影响高斯函数的宽度。较大的值会使高斯函数更宽，覆盖更大的输入空间。
- **newrbe**：使用MATLAB的`newrbe`函数创建RBF神经网络。该函数通过最小二乘法确定输出层权重，并自动计算隐层径向基函数的中心和宽度参数。

#### 7. 仿真测试

```matlab
t_sim1 = sim(net, p_train);          % 使用训练集数据进行仿真预测，得到训练集预测结果
t_sim2 = sim(net, p_test );          % 使用测试集数据进行仿真预测，得到测试集预测结果
```

- **sim**：使用训练好的RBF神经网络对输入数据进行仿真预测。
  - `t_sim1`：训练集的预测结果。
  - `t_sim2`：测试集的预测结果。

#### 8. 数据反归一化

```matlab
T_sim1 = mapminmax('reverse', t_sim1, ps_output);  % 将训练集预测结果反归一化，恢复到原始尺度
T_sim2 = mapminmax('reverse', t_sim2, ps_output);  % 将测试集预测结果反归一化，恢复到原始尺度
```

- **mapminmax('reverse', ...)**：使用`mapminmax`函数将预测结果反归一化，恢复到原始数据的尺度。
- **T_sim1**：训练集预测结果，恢复到原始尺度。
- **T_sim2**：测试集预测结果，恢复到原始尺度。

#### 9. 均方根误差（RMSE）

```matlab
error1 = sqrt(sum((T_sim1 - T_train).^2) ./ M);  % 计算训练集的均方根误差（RMSE）
error2 = sqrt(sum((T_sim2 - T_test ).^2) ./ N);  % 计算测试集的均方根误差（RMSE）
```

- **RMSE**：均方根误差，衡量模型预测值与真实值之间的平均差异。
- **error1**：训练集的RMSE，计算公式为：
  \[
  RMSE = \sqrt{\frac{1}{M} \sum_{i=1}^{M} (T_{\text{sim1}} - T_{\text{train}})^2}
  \]
- **error2**：测试集的RMSE，计算公式为：
  \[
  RMSE = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (T_{\text{sim2}} - T_{\text{test}})^2}
  \]

#### 10. 查看网络结构

```matlab
view(net)  % 可视化RBF神经网络的结构，包括输入层、隐层和输出层
```

- **view**：使用`view`函数可视化RBF神经网络的结构，展示输入层、隐层（径向基函数层）和输出层的连接方式及参数设置。

#### 11. 绘图

```matlab
% 绘制训练集预测结果对比图
figure
plot(1:M, T_train, 'r-*', 1:M, T_sim1, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'训练集预测结果对比'; ['RMSE=' num2str(error1)]};      % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, M])                                                     % 设置X轴范围
grid                                                             % 显示网格

% 绘制测试集预测结果对比图
figure
plot(1:N, T_test, 'r-*', 1:N, T_sim2, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'测试集预测结果对比'; ['RMSE=' num2str(error2)]};       % 创建标题字符串，包括RMSE值
title(string)                                                    % 添加图形标题
xlim([1, N])                                                     % 设置X轴范围
grid                                                             % 显示网格
```

- **figure**：创建新的图形窗口。
- **plot**：
  - 绘制训练集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
  - 绘制测试集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
- **legend**：添加图例，区分真实值和预测值。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **title**：设置图形的标题，包括RMSE值。
- **xlim**：设置X轴的显示范围。
- **grid**：显示网格，提升图形的可读性。

#### 12. 相关指标计算

```matlab
% R²
R1 = 1 - norm(T_train - T_sim1)^2 / norm(T_train - mean(T_train))^2;  % 计算训练集的决定系数R²
R2 = 1 - norm(T_test  - T_sim2)^2 / norm(T_test  - mean(T_test ))^2;  % 计算测试集的决定系数R²

disp(['训练集数据的R²为：', num2str(R1)])  % 显示训练集的R²
disp(['测试集数据的R²为：', num2str(R2)])  % 显示测试集的R²

% MAE
mae1 = sum(abs(T_sim1 - T_train)) ./ M ;  % 计算训练集的平均绝对误差MAE
mae2 = sum(abs(T_sim2 - T_test )) ./ N ;  % 计算测试集的平均绝对误差MAE

disp(['训练集数据的MAE为：', num2str(mae1)])  % 显示训练集的MAE
disp(['测试集数据的MAE为：', num2str(mae2)])  % 显示测试集的MAE

% MBE
mbe1 = sum(T_sim1 - T_train) ./ M ;  % 计算训练集的平均偏差误差MBE
mbe2 = sum(T_sim2 - T_test ) ./ N ;  % 计算测试集的平均偏差误差MBE

disp(['训练集数据的MBE为：', num2str(mbe1)])  % 显示训练集的MBE
disp(['测试集数据的MBE为：', num2str(mbe2)])  % 显示测试集的MBE

% MAPE
mape1 = sum(abs((T_sim1 - T_train)./T_train)) ./ M ;  % 计算训练集的平均绝对百分比误差MAPE
mape2 = sum(abs((T_sim2 - T_test )./T_test )) ./ N ;  % 计算测试集的平均绝对百分比误差MAPE

disp(['训练集数据的MAPE为：', num2str(mape1)])  % 显示训练集的MAPE
disp(['测试集数据的MAPE为：', num2str(mape2)])  % 显示测试集的MAPE

% RMSE
disp(['训练集数据的RMSE为：', num2str(error1)])  % 显示训练集的RMSE
disp(['测试集数据的RMSE为：', num2str(error2)])  % 显示测试集的RMSE
```

- **决定系数（R²）**：
  - **R1**：训练集的决定系数R²，衡量模型对训练数据的拟合程度。
  - **R2**：测试集的决定系数R²，衡量模型对测试数据的泛化能力。
  - **disp**：显示R²值。
  
- **平均绝对误差（MAE）**：
  - **mae1**：训练集的平均绝对误差，表示预测值与真实值之间的平均绝对差异。
  - **mae2**：测试集的平均绝对误差，表示预测值与真实值之间的平均绝对差异。
  - **disp**：显示MAE值。
  
- **平均偏差误差（MBE）**：
  - **mbe1**：训练集的平均偏差误差，衡量模型是否存在系统性偏差。
  - **mbe2**：测试集的平均偏差误差，衡量模型是否存在系统性偏差。
  - **disp**：显示MBE值。
  
- **平均绝对百分比误差（MAPE）**：
  - **mape1**：训练集的平均绝对百分比误差，表示预测值与真实值之间的平均绝对百分比差异。
  - **mape2**：测试集的平均绝对百分比误差，表示预测值与真实值之间的平均绝对百分比差异。
  - **disp**：显示MAPE值。
  
- **均方根误差（RMSE）**：
  - **error1**：训练集的RMSE，显示训练集的均方根误差。
  - **error2**：测试集的RMSE，显示测试集的均方根误差。

#### 13. 绘制散点图

```matlab
sz = 25;       % 设置散点大小
c = 'b';       % 设置散点颜色为蓝色

% 绘制训练集散点图
figure
scatter(T_train, T_sim1, sz, c)              % 绘制训练集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('训练集真实值');                        % 设置X轴标签
ylabel('训练集预测值');                        % 设置Y轴标签
xlim([min(T_train) max(T_train)])              % 设置X轴范围
ylim([min(T_sim1) max(T_sim1)])                % 设置Y轴范围
title('训练集预测值 vs. 训练集真实值')            % 设置图形标题

% 绘制测试集散点图
figure
scatter(T_test, T_sim2, sz, c)               % 绘制测试集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('测试集真实值');                         % 设置X轴标签
ylabel('测试集预测值');                         % 设置Y轴标签
xlim([min(T_test) max(T_test)])                 % 设置X轴范围
ylim([min(T_sim2) max(T_sim2)])                 % 设置Y轴范围
title('测试集预测值 vs. 测试集真实值')             % 设置图形标题
```

- **sz**：设置散点的大小为25。
- **c**：设置散点的颜色为蓝色。
- **scatter**：
  - 绘制训练集真实值与预测值的散点图，蓝色散点表示预测结果。
  - 绘制测试集真实值与预测值的散点图，蓝色散点表示预测结果。
- **hold on**：保持当前图形，允许在同一图形上绘制多条曲线。
- **plot(xlim, ylim, '--k')**：绘制理想预测线，即真实值等于预测值的对角线，使用黑色虚线表示。
- **xlabel** 和 **ylabel**：设置X轴和Y轴的标签。
- **title**：设置图形的标题，分别为“训练集预测值 vs. 训练集真实值”和“测试集预测值 vs. 测试集真实值”。
- **xlim** 和 **ylim**：设置X轴和Y轴的显示范围。
- **grid**：显示网格，提升图形的可读性。

---

### 代码使用注意事项

1. **数据集格式**：
   - **目标变量**：确保`数据集.xlsx`的最后一列为目标变量，且目标变量为数值型数据。如果目标变量为分类标签，需先进行数值编码。
   - **特征类型**：数据集的其他列应为数值型特征，适合进行归一化处理。如果特征包含类别变量，需先进行编码转换。

2. **参数调整**：
   - **径向基函数的扩展速度（rbf_spread）**：在`main.m`文件中通过`rbf_spread = 100`设定。根据数据集的分布和特征数量调整径向基函数的扩展速度，扩展速度过大可能导致函数过宽，过小则可能导致函数过窄，影响模型的拟合能力。
   - **网络结构**：
     - **隐层节点数**：在`main.m`文件中通过`hiddennum = 5`设定。根据数据集的复杂度和特征数量调整隐层节点数，节点数过少可能导致欠拟合，过多则可能导致过拟合。
   - **数据归一化**：
     - 确保训练集和测试集使用相同的归一化参数，以保证数据尺度一致。

3. **环境要求**：
   - **MATLAB版本**：确保使用的MATLAB版本支持`newrbe`函数。该函数属于神经网络工具箱（Neural Network Toolbox），确保已安装该工具箱。
   - **工具箱**：
     - **神经网络工具箱（Neural Network Toolbox）**：支持`newrbe`、`sim`和`view`等函数。

4. **性能优化**：
   - **数据预处理**：除了归一化处理，还可以考虑主成分分析（PCA）等降维方法，减少特征数量，提升模型训练效率和性能。
   - **网络结构优化**：通过调整隐层节点数、选择不同的径向基函数类型等方法优化网络结构，提升模型性能。
   - **径向基函数参数优化**：通过交叉验证等方法确定径向基函数的最佳扩展速度（rbf_spread），以提高模型的拟合能力和泛化能力。

5. **结果验证**：
   - **交叉验证**：采用k折交叉验证方法评估模型的稳定性和泛化能力，避免因数据划分偶然性导致的性能波动。
   - **多次运行**：由于RBF神经网络对初始参数敏感，建议多次运行模型，取平均性能指标，以获得更稳定的评估结果。
   - **模型对比**：将RBF回归模型与其他回归模型（如BP回归、支持向量回归、随机森林回归等）进行对比，评估不同模型在相同数据集上的表现差异。

6. **性能指标理解**：
   - **决定系数（R²）**：衡量模型对数据的拟合程度，值越接近1表示模型解释变量变异的能力越强。
   - **平均绝对误差（MAE）**：表示预测值与真实值之间的平均绝对差异，值越小表示模型性能越好。
   - **平均偏差误差（MBE）**：表示预测值与真实值之间的平均差异，正值表示模型倾向于高估，负值表示模型倾向于低估。
   - **平均绝对百分比误差（MAPE）**：表示预测值与真实值之间的平均绝对百分比差异，适用于评估相对误差。
   - **均方根误差（RMSE）**：表示预测值与真实值之间的平方差的平均值的平方根，值越小表示模型性能越好。

7. **网络分析与可视化**：
   - **网络结构分析**：使用`view(net)`函数可视化RBF网络的结构，便于理解网络的各层组成和参数设置。
   - **训练过程可视化**：虽然`newrbe`函数自动训练网络，但可以通过绘图函数对训练结果进行可视化，了解模型的拟合情况。

8. **代码适应性**：
   - **网络参数调整**：根据实际数据和任务需求，调整网络参数，如径向基函数的类型和扩展速度。
   - **数据格式匹配**：确保输入数据的格式与网络结构的要求一致。如果输入数据为多特征的高维数据，需相应调整网络参数和数据处理方式。

通过理解和应用上述RBF回归模型，用户可以有效地处理各种回归任务，充分发挥RBF神经网络在非线性关系建模和快速训练方面的优势，提升模型的预测准确性和鲁棒性。
