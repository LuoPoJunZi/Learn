### PSO-BP回归详细介绍

#### 什么是PSO-BP回归？

**PSO-BP回归**（粒子群优化-反向传播回归，Particle Swarm Optimization-Backpropagation Regression）是一种结合了**粒子群优化算法（Particle Swarm Optimization, PSO）**和**反向传播神经网络（Backpropagation Neural Network, BP）**的混合回归方法。该方法旨在通过粒子群优化算法优化BP神经网络的初始权重和偏置，进而利用反向传播算法进一步调整网络参数，以提高模型的预测准确性和泛化能力。

#### PSO-BP回归的组成部分

1. **粒子群优化算法（PSO）**：
   - **粒子**：每个粒子代表一个候选解，即BP网络的权重和偏置。
   - **速度与位置更新**：粒子根据自身的经验和群体的经验调整其速度和位置，逐步逼近最优解。
   - **适应度评估**：通过计算候选解的适应度值（通常基于模型的预测误差）来评估粒子的优劣。
   - **全局与个体极值**：每个粒子记录其历史最佳位置，全局记录群体中最优的位置，以指导粒子的搜索方向。

2. **反向传播神经网络（BP）**：
   - **前向传播**：计算网络的输出。
   - **误差计算**：计算输出与真实值之间的误差。
   - **反向传播**：根据误差调整网络权重和偏置，最小化误差。

#### PSO-BP回归的工作原理

PSO-BP回归通过以下步骤实现回归任务：

1. **数据准备与预处理**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建BP神经网络**：
   - **网络结构设计**：确定输入层、隐藏层和输出层的节点数，根据问题的复杂度和数据特性设计合适的网络架构。
   - **参数初始化**：使用粒子群优化算法优化网络的初始权重和偏置。

3. **粒子群优化算法优化**：
   - **编码**：将BP神经网络的权重和偏置编码为粒子的位置向量。
   - **适应度评估**：使用训练集数据评估每个粒子对应的网络性能（如RMSE）。
   - **速度与位置更新**：根据个体极值和全局极值调整粒子的速度和位置。
   - **迭代优化**：重复适应度评估、速度与位置更新，逐步优化粒子群。

4. **反向传播训练**：
   - 使用PSO优化后的权重和偏置作为BP神经网络的初始参数，进行反向传播训练，进一步调整网络参数以最小化预测误差。

5. **模型预测与评估**：
   - 使用训练好的PSO-BP模型对测试集数据进行回归预测，计算预测误差和其他性能指标。
   - 评估模型的回归准确性和泛化能力，分析模型的表现。

6. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **优化迭代曲线**：绘制粒子群优化过程中适应度值的变化曲线，观察优化效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **相关指标**：计算并显示RMSE、R²、MAE、MBE、MAPE等回归性能指标，全面评估模型性能。

#### PSO-BP回归的优势

1. **全局优化能力强**：
   - 粒子群优化算法具有良好的全局搜索能力，能够有效避免陷入局部最优，找到更优的网络参数。

2. **提高训练速度**：
   - PSO优化后的初始权重和偏置为BP提供了良好的起点，减少了BP训练的收敛时间。

3. **增强模型泛化能力**：
   - 结合PSO和BP的优势，PSO-BP回归模型具有较强的泛化能力，能够在未见数据上表现良好。

4. **适应性强**：
   - PSO-BP回归适用于多种回归任务，尤其是在参数优化困难或数据复杂的情况下表现出色。

5. **实现简单**：
   - 通过PSO和BP的组合，实现相对简单且高效的训练过程，适合不同领域的应用。

#### PSO-BP回归的应用

PSO-BP回归广泛应用于各类需要高精度预测和拟合的领域，包括但不限于：

1. **金融预测**：
   - **股票价格预测**：预测股票市场的未来价格走势。
   - **经济指标预测**：预测GDP、通胀率等宏观经济指标。

2. **工程与制造**：
   - **设备故障预测**：预测设备的潜在故障，进行预防性维护。
   - **质量控制**：拟合和预测制造过程中关键参数，确保产品质量。

3. **环境科学**：
   - **污染物浓度预测**：预测空气或水体中的污染物浓度，进行环境监测。
   - **气象预测**：预测未来的气温、降水量等气象指标。

4. **医疗健康**：
   - **疾病风险预测**：预测个体患某种疾病的风险。
   - **医疗费用预测**：预测患者的医疗费用支出。

5. **市场营销**：
   - **销售预测**：预测产品的未来销售量，优化库存管理。
   - **客户需求预测**：预测客户的购买行为和需求变化，制定营销策略。

#### 如何使用PSO-BP回归

使用PSO-BP回归模型主要包括以下步骤：

1. **准备数据集**：
   - **数据收集与整理**：确保数据的完整性和准确性，处理缺失值和异常值。
   - **数据划分**：将数据集划分为训练集和测试集，常用比例为70%训练集和30%测试集。
   - **数据预处理**：对数据进行归一化或标准化处理，以提高模型的训练效果和稳定性。

2. **构建BP神经网络**：
   - **设计网络结构**：确定输入层、隐藏层和输出层的节点数，设计合适的网络架构。
   - **参数初始化**：通过粒子群优化算法优化BP网络的初始权重和偏置。

3. **粒子群优化算法优化**：
   - **编码网络参数**：将BP网络的权重和偏置编码为粒子的位置向量。
   - **适应度评估**：使用训练集数据评估每个粒子对应的网络性能。
   - **速度与位置更新**：根据个体极值和全局极值调整粒子的速度和位置。
   - **迭代优化**：重复适应度评估和速度与位置更新，直到达到预设的终止条件。

4. **反向传播训练**：
   - 使用PSO优化后的网络参数作为BP网络的初始参数，进行反向传播训练，进一步优化网络权重和偏置。

5. **模型预测与评估**：
   - 使用训练好的PSO-BP模型对测试集数据进行回归预测，计算预测误差和其他性能指标。
   - 评估模型的回归准确性和泛化能力，分析模型的表现。

6. **结果分析与可视化**：
   - **预测结果对比图**：绘制真实值与预测值的对比图，直观展示模型的回归效果。
   - **优化迭代曲线**：绘制粒子群优化过程中适应度值的变化曲线，观察优化效果。
   - **散点图**：绘制真实值与预测值的散点图，评估模型的拟合能力。
   - **相关指标**：计算并显示RMSE、R²、MAE、MBE、MAPE等回归性能指标，全面评估模型性能。

---
    
### 代码简介

该MATLAB代码实现了基于**粒子群优化-反向传播（PSO-BP）**的回归算法，简称“PSO-BP回归”。主要包括以下文件：

1. **fun.m**：
   - 负责计算每个粒子的适应度值，即BP网络在当前权重和偏置下的预测误差。
   - 作为PSO算法的适应度评估函数。

2. **main.m**：
   - 主脚本文件，负责数据的读取、预处理、PSO-BP模型的训练与预测、结果的可视化及性能指标的计算。

以下是包含详细中文注释的PSO-BP回归MATLAB代码。

---

### MATLAB代码（添加详细中文注释）

#### fun.m 文件代码

```matlab
function error = fun(pop, hiddennum, net, p_train, t_train)
    % PSO-BP回归的适应度评估函数
    % 输入：
    %   pop        - 粒子位置向量，包含BP网络的所有权重和偏置
    %   hiddennum  - 隐藏层神经元个数
    %   net        - BP神经网络对象
    %   p_train    - 训练集输入数据
    %   t_train    - 训练集输出数据
    % 输出：
    %   error      - 适应度值，基于训练集的预测误差

    %% 节点个数
    inputnum  = size(p_train, 1);  % 输入层节点数（特征维度）
    outputnum = size(t_train, 1);  % 输出层节点数（目标维度）

    %% 提取权值和偏置
    % 从粒子位置向量中提取输入权重w1、隐层偏置B1、输出权重w2和输出层偏置B2
    w1 = pop(1 : inputnum * hiddennum);  % 输入权重向量
    B1 = pop(inputnum * hiddennum + 1 : inputnum * hiddennum + hiddennum);  % 隐层偏置向量
    w2 = pop(inputnum * hiddennum + hiddennum + 1 : ...
        inputnum * hiddennum + hiddennum + hiddennum * outputnum);  % 输出权重向量
    B2 = pop(inputnum * hiddennum + hiddennum + hiddennum * outputnum + 1 : ...
        inputnum * hiddennum + hiddennum + hiddennum * outputnum + outputnum);  % 输出层偏置向量

    %% 网络赋值
    % 将提取的权重和偏置赋值给BP神经网络对象
    net.Iw{1, 1} = reshape(w1, hiddennum, inputnum);  % 输入权重矩阵，尺寸为(hiddennum × inputnum)
    net.Lw{2, 1} = reshape(w2, outputnum, hiddennum); % 输出权重矩阵，尺寸为(outputnum × hiddennum)
    net.b{1}     = reshape(B1, hiddennum, 1);        % 隐层偏置向量，尺寸为(hiddennum × 1)
    net.b{2}     = B2';                               % 输出层偏置向量，尺寸为(1 × outputnum)

    %% 网络训练
    net = train(net, p_train, t_train);  % 使用训练集数据训练BP神经网络

    %% 仿真测试
    t_sim1 = sim(net, p_train);          % 使用训练集数据进行仿真预测，得到训练集预测结果

    %% 适应度值
    % 计算训练集预测误差的总和，作为适应度值
    error = sum(sqrt(sum((t_sim1 - t_train) .^ 2) ./ length(t_sim1)));
end
```

#### main.m 文件代码

```matlab
%% 初始化
clear                % 清除工作区变量
close all            % 关闭所有图形窗口
clc                  % 清空命令行窗口
warning off          % 关闭警告信息

%% 导入数据
res = xlsread('数据集.xlsx');  % 从Excel文件中读取数据，假设最后一列为目标变量

%% 数据分析
num_size = 0.7;                              % 设定训练集占数据集的比例（70%训练集，30%测试集）
outdim = 1;                                  % 最后一列为输出（目标变量）
num_samples = size(res, 1);                  % 计算样本个数（数据集中的行数）
res = res(randperm(num_samples), :);         % 随机打乱数据集顺序，以避免数据排序带来的偏差（如果不希望打乱可注释该行）
num_train_s = round(num_size * num_samples); % 计算训练集样本个数（四舍五入）
f_ = size(res, 2) - outdim;                  % 输入特征维度（总列数减去输出维度）

%% 划分训练集和测试集
P_train = res(1:num_train_s, 1:f_)';         % 训练集输入，转置使每列为一个样本 (f_ × M)
T_train = res(1:num_train_s, f_+1:end)';     % 训练集输出，转置使每列为一个样本 (outdim × M)
M = size(P_train, 2);                        % 训练集样本数

P_test = res(num_train_s+1:end, 1:f_)';      % 测试集输入，转置使每列为一个样本 (f_ × N)
T_test = res(num_train_s+1:end, f_+1:end)';  % 测试集输出，转置使每列为一个样本 (outdim × N)
N = size(P_test, 2);                         % 测试集样本数

%% 数据归一化
[P_train, ps_input] = mapminmax(P_train, 0, 1);         % 对训练集输入进行归一化，范围[0,1]
P_test = mapminmax('apply', P_test, ps_input);         % 使用训练集的归一化参数对测试集输入进行归一化

[t_train, ps_output] = mapminmax(T_train, 0, 1);         % 对训练集输出进行归一化，范围[0,1]
t_test = mapminmax('apply', T_test, ps_output);         % 使用训练集的归一化参数对测试集输出进行归一化

%% 节点个数
inputnum  = size(p_train, 1);  % 输入层节点数（特征维度）
hiddennum = 5;                 % 隐藏层节点数
outputnum = size(t_train, 1);  % 输出层节点数（目标维度）

%% 建立网络
net = newff(p_train, t_train, hiddennum);  % 创建BP神经网络，隐藏层节点数为hiddennum

%% 设置训练参数
net.trainParam.epochs     = 1000;      % 设置最大训练次数为1000
net.trainParam.goal       = 1e-6;      % 设置训练目标误差为1e-6
net.trainParam.lr         = 0.01;      % 设置学习率为0.01
net.trainParam.showWindow = 0;         % 关闭训练窗口，避免干扰

%% 参数初始化
c1      = 4.494;       % 学习因子1（个体认知因子）
c2      = 4.494;       % 学习因子2（社会认知因子）
maxgen  =   45;        % 粒子群优化的迭代代数
sizepop =    5;         % 粒子群优化的种群规模
Vmax    =  1.0;        % 最大速度
Vmin    = -1.0;        % 最小速度
popmax  =  1.0;        % 粒子位置最大边界
popmin  = -1.0;        % 粒子位置最小边界

%% 节点总数
% 计算BP网络的所有可优化参数数量（输入权重 + 隐层偏置 + 输出权重 + 输出层偏置）
numsum = inputnum * hiddennum + hiddennum + hiddennum * outputnum + outputnum;

%% 初始化种群和速度
for i = 1:sizepop
    pop(i, :) = rand(1, numsum) * 2 - 1;  % 初始化粒子位置，随机在[-1,1]之间
    V(i, :) = rand(1, numsum) * 2 - 1;    % 初始化粒子速度，随机在[-1,1]之间
    fitness(i) = fun(pop(i, :), hiddennum, net, p_train, t_train);  % 计算初始适应度
end

%% 个体极值和群体极值
[fitnesszbest, bestindex] = min(fitness);   % 找到群体中最优适应度值和对应粒子索引
zbest = pop(bestindex, :);                  % 全局最佳粒子位置
gbest = pop;                                % 个体最佳粒子位置（初始为当前种群位置）
fitnessgbest = fitness;                     % 个体最佳适应度值（初始为当前种群适应度）
BestFit = fitnesszbest;                     % 存储全局最佳适应度值

%% 迭代寻优
for i = 1:maxgen
    for j = 1:sizepop
        % 速度更新公式
        V(j, :) = V(j, :) + c1 * rand * (gbest(j, :) - pop(j, :)) + c2 * rand * (zbest - pop(j, :));
        % 限制速度范围
        V(j, (V(j, :) > Vmax)) = Vmax;
        V(j, (V(j, :) < Vmin)) = Vmin;
        
        % 位置更新公式
        pop(j, :) = pop(j, :) + 0.2 * V(j, :);  % 位置更新步长为0.2
        % 限制位置范围
        pop(j, (pop(j, :) > popmax)) = popmax;
        pop(j, (pop(j, :) < popmin)) = popmin;
        
        % 自适应变异
        pos = unidrnd(numsum);                   % 随机选择一个位置进行变异
        if rand > 0.85                           % 85%的概率触发变异
            pop(j, pos) = rand * 2 - 1;           % 变异为新的随机值[-1,1]
        end
        
        % 适应度值更新
        fitness(j) = fun(pop(j, :), hiddennum, net, p_train, t_train);
    end
    
    for j = 1:sizepop
        % 个体最优更新
        if fitness(j) < fitnessgbest(j)
            gbest(j, :) = pop(j, :);            % 更新个体最佳位置
            fitnessgbest(j) = fitness(j);       % 更新个体最佳适应度值
        end
        
        % 群体最优更新
        if fitness(j) < fitnesszbest
            zbest = pop(j, :);                   % 更新全局最佳位置
            fitnesszbest = fitness(j);           % 更新全局最佳适应度值
        end
    end
    
    BestFit = [BestFit, fitnesszbest];            % 记录全局最佳适应度值
end

%% 提取最优初始权值和阈值
% 从全局最佳粒子位置zbest中提取BP网络的权重和偏置
w1 = zbest(1 : inputnum * hiddennum);  % 输入权重向量
B1 = zbest(inputnum * hiddennum + 1 : inputnum * hiddennum + hiddennum);  % 隐层偏置向量
w2 = zbest(inputnum * hiddennum + hiddennum + 1 : inputnum * hiddennum ...
    + hiddennum + hiddennum * outputnum);  % 输出权重向量
B2 = zbest(inputnum * hiddennum + hiddennum + hiddennum * outputnum + 1 : ...
    inputnum * hiddennum + hiddennum + hiddennum * outputnum + outputnum);  % 输出层偏置向量

%% 最优值赋值
% 将提取的权重和偏置赋值给BP神经网络对象
net.Iw{1, 1} = reshape(w1, hiddennum, inputnum);  % 输入权重矩阵
net.Lw{2, 1} = reshape(w2, outputnum, hiddennum); % 输出权重矩阵
net.b{1}     = reshape(B1, hiddennum, 1);        % 隐层偏置向量
net.b{2}     = B2';                               % 输出层偏置向量

%% 打开训练窗口 
net.trainParam.showWindow = 1;        % 打开训练窗口，观察训练过程

%% 网络训练
net = train(net, p_train, t_train);    % 使用训练集数据进一步训练BP神经网络

%% 仿真预测
t_sim1 = sim(net, p_train);              % 使用训练集数据进行预测，得到训练集预测结果
t_sim2 = sim(net, p_test );              % 使用测试集数据进行预测，得到测试集预测结果

%% 数据反归一化
T_sim1 = mapminmax('reverse', t_sim1, ps_output);  % 将训练集预测结果反归一化，恢复到原始尺度
T_sim2 = mapminmax('reverse', t_sim2, ps_output);  % 将测试集预测结果反归一化，恢复到原始尺度

%% 均方根误差（RMSE）
error1 = sqrt(sum((T_sim1 - T_train).^2, 2)' ./ M);  % 计算训练集的均方根误差（RMSE）
error2 = sqrt(sum((T_sim2 - T_test) .^2, 2)' ./ N);  % 计算测试集的均方根误差（RMSE）

%% 绘图
% 绘制训练集预测结果对比图
figure
plot(1:M, T_train, 'r-*', 1:M, T_sim1, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'训练集预测结果对比'; ['RMSE=' num2str(error1)]};      % 创建标题字符串
title(string)                                                    % 添加图形标题
xlim([1, M])                                                     % 设置X轴范围
grid                                                             % 显示网格

% 绘制测试集预测结果对比图
figure
plot(1:N, T_test, 'r-*', 1:N, T_sim2, 'b-o', 'LineWidth', 1) % 绘制真实值与预测值对比曲线
legend('真实值', '预测值')                                        % 添加图例
xlabel('预测样本')                                                % 设置X轴标签
ylabel('预测结果')                                                % 设置Y轴标签
string = {'测试集预测结果对比'; ['RMSE=' num2str(error2)]};       % 创建标题字符串
title(string)                                                    % 添加图形标题
xlim([1, N])                                                     % 设置X轴范围
grid                                                             % 显示网格

%% 误差曲线迭代图
figure;
plot(1:length(BestFit), BestFit, 'LineWidth', 1.5);  % 绘制粒子群优化过程中适应度值的变化曲线
xlabel('粒子群迭代次数');                              % 设置X轴标签
ylabel('适应度值');                                    % 设置Y轴标签
xlim([1, length(BestFit)])                             % 设置X轴范围
title('模型迭代误差变化');                              % 设置图形标题
grid on                                                 % 显示网格

%% 相关指标计算
% R²
R1 = 1 - norm(T_train - T_sim1)^2 / norm(T_train - mean(T_train))^2;  % 计算训练集的决定系数R²
R2 = 1 - norm(T_test  - T_sim2)^2 / norm(T_test  - mean(T_test ))^2;  % 计算测试集的决定系数R²

disp(['训练集数据的R²为：', num2str(R1)])  % 显示训练集的R²
disp(['测试集数据的R²为：', num2str(R2)])  % 显示测试集的R²

% MAE
mae1 = sum(abs(T_sim1 - T_train), 2)' ./ M ;  % 计算训练集的平均绝对误差MAE
mae2 = sum(abs(T_sim2 - T_test ), 2)' ./ N ;  % 计算测试集的平均绝对误差MAE

disp(['训练集数据的MAE为：', num2str(mae1)])  % 显示训练集的MAE
disp(['测试集数据的MAE为：', num2str(mae2)])  % 显示测试集的MAE

% MBE
mbe1 = sum(T_sim1 - T_train, 2)' ./ M ;  % 计算训练集的平均偏差误差MBE
mbe2 = sum(T_sim2 - T_test , 2)' ./ N ;  % 计算测试集的平均偏差误差MBE

disp(['训练集数据的MBE为：', num2str(mbe1)])  % 显示训练集的MBE
disp(['测试集数据的MBE为：', num2str(mbe2)])  % 显示测试集的MBE

% MAPE
mape1 = sum(abs((T_sim1 - T_train)./T_train)) ./ M ;  % 计算训练集的平均绝对百分比误差MAPE
mape2 = sum(abs((T_sim2 - T_test )./T_test )) ./ N ;  % 计算测试集的平均绝对百分比误差MAPE

disp(['训练集数据的MAPE为：', num2str(mape1)])  % 显示训练集的MAPE
disp(['测试集数据的MAPE为：', num2str(mape2)])  % 显示测试集的MAPE

% RMSE
disp(['训练集数据的RMSE为：', num2str(error1)])  % 显示训练集的RMSE
disp(['测试集数据的RMSE为：', num2str(error2)])  % 显示测试集的RMSE

%% 绘制散点图
sz = 25;       % 设置散点大小
c = 'b';       % 设置散点颜色为蓝色

% 绘制训练集散点图
figure
scatter(T_train, T_sim1, sz, c)              % 绘制训练集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('训练集真实值');                        % 设置X轴标签
ylabel('训练集预测值');                        % 设置Y轴标签
xlim([min(T_train) max(T_train)])              % 设置X轴范围
ylim([min(T_sim1) max(T_sim1)])                % 设置Y轴范围
title('训练集预测值 vs. 训练集真实值')            % 设置图形标题

% 绘制测试集散点图
figure
scatter(T_test, T_sim2, sz, c)               % 绘制测试集真实值与预测值的散点图
hold on                                       % 保持图形
plot(xlim, ylim, '--k')                       % 绘制理想预测线（真实值等于预测值的对角线）
xlabel('测试集真实值');                         % 设置X轴标签
ylabel('测试集预测值');                         % 设置Y轴标签
xlim([min(T_test) max(T_test)])                 % 设置X轴范围
ylim([min(T_sim2) max(T_sim2)])                 % 设置Y轴范围
title('测试集预测值 vs. 测试集真实值')             % 设置图形标题
```

---

### 代码说明

#### 1. fun.m 文件说明

`fun.m` 是PSO-BP回归中的适应度评估函数，负责计算每个粒子的适应度值，即BP网络在当前权重和偏置下的预测误差。

- **输入参数**：
  - `pop`：粒子位置向量，包含BP网络的所有权重和偏置。
  - `hiddennum`：隐藏层神经元个数。
  - `net`：BP神经网络对象。
  - `p_train`：训练集输入数据。
  - `t_train`：训练集输出数据。

- **输出参数**：
  - `error`：适应度值，基于训练集的预测误差。

**主要步骤**：

1. **节点个数**：
   - 确定输入层和输出层的节点数（特征维度和目标维度）。

2. **提取权值和偏置**：
   - 从粒子位置向量`pop`中提取输入权重`w1`、隐层偏置`B1`、输出权重`w2`和输出层偏置`B2`。

3. **网络赋值**：
   - 将提取的权重和偏置赋值给BP神经网络对象`net`的相应部分。

4. **网络训练**：
   - 使用训练集数据训练BP神经网络，更新网络参数。

5. **仿真测试**：
   - 使用训练集数据进行仿真预测，得到训练集的预测结果`t_sim1`。

6. **适应度值计算**：
   - 通过计算训练集预测结果与真实值之间的均方根误差（RMSE）的总和，作为适应度值`error`。适应度值越小，表示模型性能越好。

#### 2. main.m 文件说明

`main.m` 是PSO-BP回归的主脚本文件，负责数据的读取、预处理、PSO优化、BP训练与预测、结果的可视化及性能指标的计算。

**主要步骤**：

1. **初始化**：
   - 清除工作区变量、关闭所有图形窗口、清空命令行窗口、关闭警告信息，确保代码运行环境的干净和无干扰。

2. **导入数据**：
   - 使用`xlsread`函数从Excel文件`数据集.xlsx`中读取数据，假设数据集的最后一列为目标变量（需要预测的值），其他列为输入特征。

3. **数据分析**：
   - 设定训练集占数据集的比例为70%（`num_size = 0.7`）。
   - 设定数据集的最后一列为输出（目标变量，`outdim = 1`）。
   - 计算数据集中的样本总数`num_samples`。
   - 使用`randperm`函数随机打乱数据集的顺序，以避免数据排序带来的偏差。如果不希望打乱数据集，可以注释掉该行代码。
   - 计算训练集的样本数量`num_train_s`。
   - 计算输入特征的维度`f_`（总列数减去输出维度）。

4. **划分训练集和测试集**：
   - 提取前`num_train_s`个样本的输入特征和输出目标作为训练集，并进行转置，使每列为一个样本（矩阵尺寸：输入特征维度 × 样本数）。
   - 提取剩余样本的输入特征和输出目标作为测试集，并进行转置，使每列为一个样本。
   - 获取训练集和测试集的样本数量`M`和`N`。

5. **数据归一化**：
   - 使用`mapminmax`函数将训练集输入数据缩放到[0,1]的范围内，并保存归一化参数`ps_input`。
   - 使用训练集的归一化参数对测试集输入数据进行同样的归一化处理，确保训练集和测试集的数据尺度一致。
   - 同样地，对训练集和测试集的输出数据进行归一化处理，保存归一化参数`ps_output`。
   - 使用`mapminmax('apply', ...)`函数对测试集数据进行归一化。

6. **节点个数**：
   - 确定输入层、隐藏层和输出层的节点数。
   - `inputnum`：输入层节点数（特征维度）。
   - `hiddennum`：隐藏层节点数（设定为5）。
   - `outputnum`：输出层节点数（目标维度）。

7. **建立网络**：
   - 使用`newff`函数创建前馈BP神经网络，隐藏层节点数为`hiddennum`。

8. **设置训练参数**：
   - 设置BP网络的训练参数：
     - `epochs`：最大训练次数为1000次。
     - `goal`：训练目标误差为1e-6。
     - `lr`：学习率为0.01。
     - `showWindow`：关闭训练窗口，避免训练过程中的界面干扰。

9. **参数初始化**：
   - 设定PSO算法的参数：
     - `c1` 和 `c2`：学习因子，控制粒子更新时对个体和群体极值的依赖程度。
     - `maxgen`：PSO算法的最大迭代代数（45）。
     - `sizepop`：PSO算法的种群规模（5）。
     - `Vmax` 和 `Vmin`：粒子速度的最大和最小限制。
     - `popmax` 和 `popmin`：粒子位置的最大和最小边界。

10. **节点总数**：
    - 计算BP网络的所有可优化参数数量，包括输入权重、隐层偏置、输出权重和输出层偏置。

11. **初始化种群和速度**：
    - 使用`rand`函数随机初始化粒子的位置和速度，范围为[-1,1]。
    - 计算每个粒子的初始适应度值，调用`fun`函数。

12. **个体极值和群体极值**：
    - 找到群体中最优适应度值和对应粒子索引，记录全局最佳粒子`zbest`。
    - 初始化个体最佳粒子`gbest`和个体最佳适应度值`fitnessgbest`。
    - 记录全局最佳适应度值`BestFit`。

13. **迭代寻优**：
    - 进行PSO算法的迭代优化，共进行`maxgen`代迭代。
    - 在每一代中：
      - **速度更新**：根据个体认知因子和社会认知因子调整粒子的速度。
      - **速度限制**：将速度限制在`Vmax`和`Vmin`之间。
      - **位置更新**：根据更新后的速度调整粒子的位置。
      - **位置限制**：将位置限制在`popmax`和`popmin`之间。
      - **自适应变异**：以一定概率随机改变粒子的位置，增加种群多样性。
      - **适应度值更新**：重新计算粒子的适应度值。
    - **个体最优更新**：如果当前适应度优于历史最佳，更新个体最佳位置和适应度值。
    - **群体最优更新**：如果当前适应度优于全局最佳，更新全局最佳位置和适应度值。
    - **记录全局最佳适应度值**：将当前代的全局最佳适应度值记录下来，用于绘制优化迭代曲线。

14. **提取最优初始权值和阈值**：
    - 从全局最佳粒子位置`zbest`中提取BP网络的输入权重`w1`、隐层偏置`B1`、输出权重`w2`和输出层偏置`B2`。

15. **最优值赋值**：
    - 将提取的权重和偏置赋值给BP神经网络对象`net`的相应部分。

16. **打开训练窗口**：
    - 设置`showWindow`为1，打开训练窗口，观察BP网络的训练过程。

17. **网络训练**：
    - 使用训练集数据进一步训练BP神经网络，优化网络参数。

18. **仿真预测**：
    - 使用训练好的BP网络对训练集和测试集数据进行预测，得到预测结果`t_sim1`和`t_sim2`。

19. **数据反归一化**：
    - 使用`mapminmax('reverse', ...)`函数将预测结果反归一化，恢复到原始数据的尺度，得到`T_sim1`和`T_sim2`。

20. **均方根误差（RMSE）**：
    - 计算训练集和测试集的均方根误差`error1`和`error2`，衡量模型的回归性能。

21. **绘图**：
    - **训练集预测结果对比图**：
      - 使用`plot`函数绘制训练集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
      - 添加图例、坐标轴标签、标题和网格，提升图形的可读性。
      - 设置X轴范围为[1, M]。
    - **测试集预测结果对比图**：
      - 使用`plot`函数绘制测试集的真实值与预测值对比曲线，红色星号表示真实值，蓝色圆圈表示预测值。
      - 添加图例、坐标轴标签、标题和网格，提升图形的可读性。
      - 设置X轴范围为[1, N]。

22. **误差曲线迭代图**：
    - 使用`plot`函数绘制粒子群优化过程中适应度值的变化曲线，观察优化效果。
    - 设置X轴为迭代次数，Y轴为适应度值。
    - 添加标题和网格，提升图形的可读性。

23. **相关指标计算**：
    - **决定系数（R²）**：
      - 计算训练集和测试集的决定系数`R1`和`R2`，衡量模型对数据的拟合程度。
      - 使用`disp`函数显示R²值。
    - **平均绝对误差（MAE）**：
      - 计算训练集和测试集的平均绝对误差`mae1`和`mae2`。
      - 使用`disp`函数显示MAE值。
    - **平均偏差误差（MBE）**：
      - 计算训练集和测试集的平均偏差误差`mbe1`和`mbe2`，衡量模型是否存在系统性偏差。
      - 使用`disp`函数显示MBE值。
    - **平均绝对百分比误差（MAPE）**：
      - 计算训练集和测试集的平均绝对百分比误差`mape1`和`mape2`。
      - 使用`disp`函数显示MAPE值。
    - **均方根误差（RMSE）**：
      - 使用`disp`函数显示训练集和测试集的RMSE值。

24. **绘制散点图**：
    - **训练集散点图**：
      - 使用`scatter`函数绘制训练集真实值与预测值的散点图，蓝色散点表示预测结果。
      - 使用`plot`函数绘制理想预测线（真实值等于预测值的对角线），使用黑色虚线表示。
      - 设置坐标轴标签、图形标题、轴范围，并显示网格。
    - **测试集散点图**：
      - 使用`scatter`函数绘制测试集真实值与预测值的散点图，蓝色散点表示预测结果。
      - 使用`plot`函数绘制理想预测线（真实值等于预测值的对角线），使用黑色虚线表示。
      - 设置坐标轴标签、图形标题、轴范围，并显示网格。

---

### 代码使用注意事项

1. **数据集格式**：
   - **目标变量**：确保`数据集.xlsx`的最后一列为目标变量，且目标变量为数值型数据。如果目标变量为分类标签，需先进行数值编码。
   - **特征类型**：数据集的其他列应为数值型特征，适合进行归一化处理。如果特征包含类别变量，需先进行编码转换。

2. **参数调整**：
   - **隐藏层神经元数量（hiddennum）**：在`main.m`文件中通过`hiddennum = 5`设定。根据数据集的复杂度和特征数量调整隐藏层的神经元数量，神经元数量过少可能导致欠拟合，过多则可能导致过拟合。
   - **PSO算法参数**：
     - **学习因子（c1, c2）**：通过`c1 = 4.494`和`c2 = 4.494`设置，控制粒子更新时对个体和群体极值的依赖程度。可根据具体问题调整。
     - **最大迭代代数（maxgen）**：通过`maxgen = 45`设置PSO算法的迭代代数。根据问题的复杂度和计算资源调整，增加迭代代数可能提升优化效果，但也增加计算时间。
     - **种群规模（sizepop）**：通过`sizepop = 5`设置PSO算法的种群规模。较大的种群规模有助于提高搜索空间的覆盖率，但增加计算开销。
     - **速度和位置边界（Vmax, Vmin, popmax, popmin）**：通过`Vmax = 1.0`、`Vmin = -1.0`、`popmax = 1.0`和`popmin = -1.0`设置粒子速度和位置的边界范围。根据具体问题调整边界范围。
     - **自适应变异**：在PSO算法中引入自适应变异机制，增加种群多样性，防止陷入局部最优。调整变异概率（如`rand > 0.85`）以控制变异频率。

   - **BP训练参数**：
     - **最大训练次数（epochs）**：通过`net.trainParam.epochs = 1000`设置BP网络的最大训练次数。根据训练误差的收敛情况调整训练次数，以避免过早停止或不必要的计算资源浪费。
     - **训练目标误差（goal）**：通过`net.trainParam.goal = 1e-6`设置BP网络的训练目标误差。根据实际需求调整误差阈值，确保模型达到所需的精度。
     - **学习率（lr）**：通过`net.trainParam.lr = 0.01`设置BP网络的学习率。学习率影响权重更新的步长，较大的学习率可能加快收敛速度，但可能导致震荡或发散；较小的学习率则使收敛更稳定，但可能需要更多的迭代次数。
     - **训练窗口显示（showWindow）**：通过`net.trainParam.showWindow = 0`关闭训练窗口，避免在PSO优化过程中弹出训练界面。如果需要观察BP训练过程，可设置为`1`。

3. **环境要求**：
   - **MATLAB版本**：确保使用的MATLAB版本支持`newff`函数以及粒子群优化相关函数。如果使用较新的MATLAB版本，`newff`函数已被`feedforwardnet`替代，根据实际使用的MATLAB版本调整函数调用。
   - **工具箱**：
     - **神经网络工具箱（Neural Network Toolbox）**：支持`newff`、`train`和`sim`等函数。
     - **全局优化工具箱（Global Optimization Toolbox）**：支持PSO算法相关函数（如果使用自定义PSO函数，确保其正确实现）。

4. **性能优化**：
   - **数据预处理**：除了归一化处理，还可以考虑主成分分析（PCA）等降维方法，减少特征数量，提升模型训练效率和性能。
   - **网络结构优化**：通过调整隐藏层的神经元数量、增加或减少隐藏层层数、选择不同的激活函数等方法优化网络结构，提升模型性能。
   - **PSO算法优化**：
     - **增加种群规模和迭代代数**：可以提高优化效果，但需权衡计算时间。
     - **调整学习因子（c1, c2）**：适当调整学习因子以平衡探索与开发能力。
     - **自适应变异策略**：根据优化进展动态调整变异概率，进一步提升搜索效果。
   - **正则化**：在BP训练过程中，可以引入正则化方法（如L2正则化）以防止模型过拟合，提高泛化能力。

5. **结果验证**：
   - **交叉验证**：采用k折交叉验证方法评估模型的稳定性和泛化能力，避免因数据划分偶然性导致的性能波动。
   - **多次运行**：由于PSO和BP神经网络对初始权重敏感，建议多次运行模型，取平均性能指标，以获得更稳定的评估结果。
   - **模型对比**：将PSO-BP回归模型与其他回归模型（如传统BP回归、遗传算法BP回归、支持向量回归、随机森林回归等）进行对比，评估不同模型在相同数据集上的表现差异。

6. **性能指标理解**：
   - **决定系数（R²）**：衡量模型对数据的拟合程度，值越接近1表示模型解释变量变异的能力越强。
   - **平均绝对误差（MAE）**：表示预测值与真实值之间的平均绝对差异，值越小表示模型性能越好。
   - **平均偏差误差（MBE）**：表示预测值与真实值之间的平均差异，正值表示模型倾向于高估，负值表示模型倾向于低估。
   - **平均绝对百分比误差（MAPE）**：表示预测值与真实值之间的平均绝对百分比差异，适用于评估相对误差。
   - **均方根误差（RMSE）**：表示预测值与真实值之间的平方差的平均值的平方根，值越小表示模型性能越好。

7. **网络分析与可视化**：
   - **网络结构分析**：可以使用`view(net)`函数可视化BP神经网络的结构，便于理解网络的各层组成和参数设置。
   - **训练过程可视化**：通过打开训练窗口（`showWindow = 1`），实时观察训练误差的变化，了解模型的收敛情况。
   - **优化过程可视化**：通过绘制PSO优化过程中适应度值的变化曲线，观察优化效果，了解模型的优化进展。

8. **代码适应性**：
   - **网络层调整**：根据实际数据和任务需求，调整网络层的数量和参数，例如增加更多的隐藏层、调整隐藏层神经元数量、修改学习率等。
   - **适应度函数调整**：确保`fun.m`函数正确实现，能够准确评估粒子的适应度。根据需要，可以修改适应度计算方式以适应不同的优化目标或网络结构。
   - **自定义PSO算法**：如果需要更复杂的PSO优化策略，可以根据具体需求扩展和修改PSO算法的实现。

通过理解和应用上述PSO-BP回归模型，用户可以有效地处理各种回归任务，充分发挥粒子群优化在全局优化和BP神经网络在局部优化方面的优势，提升模型的预测准确性和鲁棒性。
